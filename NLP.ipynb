{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMp+g7D1rhP6TcDPb/afKo6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8haqhocsyrXK","executionInfo":{"status":"ok","timestamp":1601432183662,"user_tz":300,"elapsed":19942,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"bdb91ad1-18c9-414b-a21e-4003f1a4d95d","colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","spark_version = 'spark-3.0.1'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","\r0% [Waiting for headers] [Connected to cloud.r-project.org (13.225.71.37)] [Con\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connected to cloud.r-proje\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n","\r                                                                               \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rIgn:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","\r                                                                         \r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers]\r                                                   \rHit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 88.7 kB] [Connecting to ppa.launchpad.net (91.189.95.83)] \r                                                                               \rHit:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UzrAqXlwyxh6","executionInfo":{"status":"ok","timestamp":1601432198382,"user_tz":300,"elapsed":9133,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"tb2zaIHjy8p6","executionInfo":{"status":"ok","timestamp":1601432216679,"user_tz":300,"elapsed":449,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# import tokenizer library for NLP\n","from pyspark.ml.feature import Tokenizer"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LaQARx4zGKH","executionInfo":{"status":"ok","timestamp":1601432361008,"user_tz":300,"elapsed":3822,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"0446df33-5101-4ef8-9535-1f73588e050f","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["# create DF\n","dataframe = spark.createDataFrame([\n","                                   (0, 'Spark is great.'),\n","                                   (1, 'We are learning Spark.'),\n","                                   (2, 'Spark is better than Hadoop no doibt')\n","], ['id', 'sentence'])\n","dataframe.show()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|     Spark is great.|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jAEwRV9kzl0v","executionInfo":{"status":"ok","timestamp":1601432375005,"user_tz":300,"elapsed":330,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"d4352d5d-9c2e-4d62-97b5-31f9360d1680","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","tokenizer"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_1cb677131f4f"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"A39gDiLOzs13","executionInfo":{"status":"ok","timestamp":1601432474106,"user_tz":300,"elapsed":779,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"a506b67e-8f91-4fe0-ba1e-d34f50f44978","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["tokenized_df = tokenizer.transform(dataframe)\n","tokenized_df.show(truncate=False)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+\n","|id |sentence                            |words                                       |\n","+---+------------------------------------+--------------------------------------------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|\n","+---+------------------------------------+--------------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o_lWLh580E7O","executionInfo":{"status":"ok","timestamp":1601432568806,"user_tz":300,"elapsed":265,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# make user define function (UDF) that takes list of words in and return list length\n","# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"GE9-maFx0cK2","executionInfo":{"status":"ok","timestamp":1601432589307,"user_tz":300,"elapsed":252,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# Next, we'll import the udf function, the col function to select a column to be passed into a function, \n","# and the type IntegerType that will be used in our udf to define the data type of the output\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"3qn6zNh_0PYm","executionInfo":{"status":"ok","timestamp":1601432668939,"user_tz":300,"elapsed":279,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"PESLhMHL00nV","executionInfo":{"status":"ok","timestamp":1601432787628,"user_tz":300,"elapsed":1255,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"04c12f3d-6ccf-4b19-9bbc-1e32c1d8e976","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","# transform DF\n","tokenized_df = tokenizer.transform(dataframe)\n","# select needed columns and don't truncate results\n","tokenized_df.withColumn('tokens', count_tokens(col('words'))).show(truncate= False)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |3     |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |4     |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RxiuMo2x1M2e"},"source":[""],"execution_count":null,"outputs":[]}]}