{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_stopWords.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMtaombX7z7yu5nzQVF5aj4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"w6I9-zUq1ukv","executionInfo":{"status":"ok","timestamp":1601433005805,"user_tz":300,"elapsed":77932,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"089c6553-ff34-4984-a0d7-2323dd5db9af","colab":{"base_uri":"https://localhost:8080/","height":354}},"source":["import os\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n","spark_version = 'spark-3.0.1'\n","os.environ['SPARK_VERSION']=spark_version\n","\n","# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","\n","# Set Environment Variables\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n","\n","# Start a SparkSession\n","import findspark\n","findspark.init()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Get:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [908 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,435 kB]\n","Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,673 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,115 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,406 kB]\n","Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [856 kB]\n","Fetched 7,665 kB in 4s (1,992 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eC8pTAOU15A0","executionInfo":{"status":"ok","timestamp":1601433020971,"user_tz":300,"elapsed":8362,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":[" # Start Spark session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WN9qXBxd19tr","executionInfo":{"status":"ok","timestamp":1601433145654,"user_tz":300,"elapsed":6346,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"96910ec4-b422-47cb-f482-936bdd769c83","colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["# create DF\n","sentenceData = spark.createDataFrame([\n","                                      (0, ['Big', 'data', 'is', 'super', 'powerful']),\n","                                      (1, ['This', 'is', 'going', 'to', 'be', 'epic'])\n","], ['id', 'raw'])\n","\n","sentenceData.show(truncate= False)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["+---+--------------------------------+\n","|id |raw                             |\n","+---+--------------------------------+\n","|0  |[Big, data, is, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |\n","+---+--------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ISobMMCc2nhN","executionInfo":{"status":"ok","timestamp":1601433177237,"user_tz":300,"elapsed":367,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# remove stop words\n","# Import stop words library\n","from pyspark.ml.feature import StopWordsRemover"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-tULCLZ2kL0","executionInfo":{"status":"ok","timestamp":1601433191575,"user_tz":300,"elapsed":415,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# Run the Remover\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ucY0miwr2zCd","executionInfo":{"status":"ok","timestamp":1601433244405,"user_tz":300,"elapsed":1625,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"53137880-1c08-4af6-d505-8155d7c8a959","colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["# transform and show new DF\n","remover.transform(sentenceData).show(truncate= False)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["+---+--------------------------------+----------------------------+\n","|id |raw                             |filtered                    |\n","+---+--------------------------------+----------------------------+\n","|0  |[Big, data, is, super, powerful]|[Big, data, super, powerful]|\n","|1  |[This, is, going, to, be, epic] |[going, epic]               |\n","+---+--------------------------------+----------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SQLQFpPW3Ax1","executionInfo":{"status":"ok","timestamp":1601433301690,"user_tz":300,"elapsed":587,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"25621ddc-a6e6-4fe4-af94-eb55c8f2fed9","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["# create DF\n","df = spark.createDataFrame([\n","                                   (0, 'Spark is great.'),\n","                                   (1, 'We are learning Spark.'),\n","                                   (2, 'Spark is better than Hadoop no doibt')\n","], ['id', 'sentence'])\n","df.show(truncate=False)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+\n","|id |sentence                            |\n","+---+------------------------------------+\n","|0  |Spark is great.                     |\n","|1  |We are learning Spark.              |\n","|2  |Spark is better than Hadoop no doibt|\n","+---+------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n0nv1-5M3PBN","executionInfo":{"status":"ok","timestamp":1601433454261,"user_tz":300,"elapsed":261,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# Next, we'll import the udf function, the col function to select a column to be passed into a function, \n","# and the type IntegerType that will be used in our udf to define the data type of the output\n","from pyspark.sql.functions import col, udf\n","from pyspark.sql.types import IntegerType\n","\n","# import tokenizer library for NLP\n","from pyspark.ml.feature import Tokenizer\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"o039Y2Wb3pq6","executionInfo":{"status":"ok","timestamp":1601433456062,"user_tz":300,"elapsed":313,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# make user define function (UDF) that takes list of words in and return list length\n","# Create a function to return the length of a list\n","def word_list_length(word_list):\n","    return len(word_list)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"coLA-03O3nuv","executionInfo":{"status":"ok","timestamp":1601433457607,"user_tz":300,"elapsed":308,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# Create a user defined function\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKV1oHHN3oeU","executionInfo":{"status":"ok","timestamp":1601433464786,"user_tz":300,"elapsed":285,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":[""],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"JrBX9x8C3WT1","executionInfo":{"status":"ok","timestamp":1601433466887,"user_tz":300,"elapsed":1170,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"d9a30129-8e4a-43db-9e17-2cdc1a5239b0","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","# transform DF\n","tokenized_df = tokenizer.transform(df)\n","# select needed columns and don't truncate results\n","tokenized_df.withColumn('tokens', count_tokens(col('words'))).show(truncate= False)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |3     |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |4     |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hrz7RLVO4vWk","executionInfo":{"status":"ok","timestamp":1601433779002,"user_tz":300,"elapsed":320,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}}},"source":["# Run the Remover\n","remover2 = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"akLBJ01o3g4V","executionInfo":{"status":"ok","timestamp":1601433930875,"user_tz":300,"elapsed":797,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"1637b5cc-fa23-4d9f-a7b2-ba7299e4be67","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["# transform and show new DF\n","remover2.transform(tokenized_df).show(truncate= False)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |[spark, great.]               |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |[learning, spark.]            |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|[spark, better, hadoop, doibt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Guz0VAAW5sEO"},"source":["toeknize and remove stop words all in one step below"]},{"cell_type":"code","metadata":{"id":"rDwI1MsY3cws","executionInfo":{"status":"ok","timestamp":1601433998169,"user_tz":300,"elapsed":473,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"71b57d1b-d044-4f19-c9ec-fa576fab7d6f","colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["# create DF\n","df2 = spark.createDataFrame([\n","                                   (0, 'Spark is great.'),\n","                                   (1, 'We are learning Spark.'),\n","                                   (2, 'Spark is better than Hadoop no doibt')\n","], ['id', 'sentence'])\n","df2.show(truncate=False)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+\n","|id |sentence                            |\n","+---+------------------------------------+\n","|0  |Spark is great.                     |\n","|1  |We are learning Spark.              |\n","|2  |Spark is better than Hadoop no doibt|\n","+---+------------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6iE_t2Zx56R-","executionInfo":{"status":"ok","timestamp":1601434073600,"user_tz":300,"elapsed":1268,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"2af38099-42a6-4314-bfab-220f99ff85e3","colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","# transform DF\n","tokenized_df2 = tokenizer.transform(df2)\n","# select needed columns and don't truncate results\n","tokenized_df2.withColumn('tokens', count_tokens(col('words'))).show(truncate= False)\n","remover2.transform(tokenized_df).show(truncate= False)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |3     |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |4     |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |[spark, great.]               |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |[learning, spark.]            |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|[spark, better, hadoop, doibt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PHm8cJGx6LTo","executionInfo":{"status":"ok","timestamp":1601434376988,"user_tz":300,"elapsed":833,"user":{"displayName":"Byron Brunson","photoUrl":"","userId":"17524329226243340412"}},"outputId":"be7f9b1d-7b55-40d7-b106-03fcacce1418","colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["# Tokenize sentences\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n","# transform DF\n","tokenized_df2 = tokenizer.transform(df2)\n","\n","# Run the Remover\n","remover3 = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n","\n","# select needed columns and don't truncate results\n","tokenized_df2.withColumn('tokens', count_tokens(col('words'))).show(truncate= False)\n","\n","remover3.transform(tokenized_df2).show(truncate= False)\n"],"execution_count":38,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |3     |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |4     |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great.                     |[spark, is, great.]                         |[spark, great.]               |\n","|1  |We are learning Spark.              |[we, are, learning, spark.]                 |[learning, spark.]            |\n","|2  |Spark is better than Hadoop no doibt|[spark, is, better, than, hadoop, no, doibt]|[spark, better, hadoop, doibt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"],"name":"stdout"}]}]}